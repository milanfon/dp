\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[czech]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{svg}
\usepackage{float}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{csquotes}
\usepackage[acronym]{glossaries}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{pdflscape}
\usepackage{multirow}
\usepackage{array}

\geometry{
    a4paper,
    left=30mm,
    right=25mm,
    top=25mm
}

\MakeOuterQuote{"}

\setlength{\parskip}{1em}

% \usepackage[T1]{fontenc}
% \fontfamily{bch}\selectfont
\usepackage{newtxtext,newtxmath}

% Slovník
\makeglossaries
\input{gloss.tex}

%Tikz
\usetikzlibrary{shapes,arrows,quotes,babel,matrix,fit,positioning}
\tikzstyle{block} = [draw, rectangle, inner sep=1em]
\tikzstyle{sum} = [draw, circle]
\tikzstyle{mtitle} = [draw=none, color=gray, inner sep=0pt,font=\bfseries]
\tikzstyle{mmatrix} = [matrix of nodes, nodes=typetag, row sep=1em]
\tikzstyle{typetag} = [draw=gray, inner sep=1ex, anchor=west]

\begin{document}
    % Titulní strana TODO
    \begin{titlepage}
        \begin{center}
            \vspace*{1cm}

            \Large
            \textbf{
                Západočeská univerzita v Plzni\\
                Fakulta aplikovaných věd\\
                Katedra informatiky\\
                }

            \vfill

            \Huge
            \textbf{}\\
            \vspace*{1cm}
            \Large
            {DIPLOMOVÁ PRÁCE}

            \vfill

            \includegraphics[width=0.4\textwidth]{pic/fav.jpg}

            \vspace*{3cm}

            \Large
            \textbf{PLZEŇ, 2024} \hfill \textbf{Milan Horínek}
            
        \end{center}
    \end{titlepage}

    % TODO: Prohlášení
    \hspace{0pt}
    \vfill

    \begin{center}
        \Large\textbf{PROHLÁŠENÍ}
    \end{center}    
    
    \vspace*{0.5cm}
        
    \noindent 
    Předkládám tímto k posouzení a obhajobě bakalářskou práci zpracovanou na
    závěr studia na Fakultě aplikovaných věd Západočeské univerzity v Plzni.
    \\\\
    Prohlašuji, že jsem bakalářskou práci vypracoval samostatně a výhradně
    s použitím odborné literatury a pramenů, jejichž úplný seznam je její součástí.
    \\\\
    V Plzni dne \today \\\\ 
    \begin{tabular}{p{10cm}p{5cm}}
        &   \dotfill \\
        &   \centering Milan Horínek
    \end{tabular}

    \vspace*{3cm}

    \begin{center}
        \Large{\textbf{PODĚKOVÁNÍ}}
    \end{center}

    % TODO: Prohlášení
    TDB

    \vfill
    \pagebreak

    % Abstrakt / Anotace

    \hspace{0pt}
    \vfill

    \begin{center}
        \Large
        \textbf{ANOTACE}
    \end{center}

    \vspace*{0.5cm}

    \noindent TDB

    \noindent\textbf{Klíčová slova:} jednotkové testy, LLM, strojové učení, automatizace

    \vspace*{3cm}

    \begin{center}
        \Large
        \textbf{ABSTRACT}
    \end{center}

    \vspace*{0.5cm}

    \noindent TBD

    \noindent\textbf{Key words:} unit test, LLM, machine learning, automation

    \vfill
    \pagebreak

    \hspace{0pt}
    \vfill

    \begin{center}
        \Large
        \bf
        ZADÁNÍ
    \end{center}
    \vspace*{5mm}
    \begin{enumerate}
        \item Seznamte se s existujícími LLM, jejich technologií a možnostmi použití.
        \item Prostudujte exitující literaturu ohledně genrování jednotkových testů, zejména s ohledem na využití neuronových sítí a LLM.
        \item Seznamte se s existujícími ukázkovými programy s možností injekce chyb a vyberte vhodný testovací program. Navrhněte a implementujte automatizovaný nástroj využívající popis testu v přirozené řeči, LLM a případně další informace, který vygeneruje sadu jednotkových testů.
        \item Ověřte kvalitu automaticky vytvořených testů zejména s ohledem na přesnost a úplnost.
        \item Zhodnoťte možnosti současných LLM pro generování testů.
    \end{enumerate}

    \vspace*{3cm}

    \begin{center}
        \Large
        \bf
        ASSIGNMENT
    \end{center}
    \vspace*{5mm}
    \begin{enumerate}
        \item Familiarize yourself with existing Large Language Models (LLMs), their technology, and application possibilities.
        \item Study the existing literature regarding the generation of unit tests, especially with regards to the use of neural networks and LLMs.
        \item Familiarize yourself with existing sample programs with the possibility of error injection and select a suitable test program. Design and implement an automated tool using the test description in natural language, LLMs, and possibly additional information, which will generate a set of unit tests.
        \item Verify the quality of the automatically created tests, particularly with regards to accuracy and completeness.
        \item Evaluate the possibilities of current LLMs for test generation.
    \end{enumerate}

    \vfill
    \pagebreak

    % Obsah
    \newpage
    \tableofcontents

    % Slovník
    \newpage
    \printglossary[type=\acronymtype,title=Zkratky]
    \printglossary[title=Slovník pojmů]

    \newpage
    \section{Úvod}
    %TODO Dopsat - co jsou unit testy a jejich předpoklady, co jsou LLM
    TDB - Co jsou unit testy, LLM, a jejich předpoklady

    \newpage
    \section{Provedená práce v problematice} \label{sec:previouswork}

        \subsection{Předchozí automatizovaná řešení}
        Jazykové modely nebyli prvními pokusy o automatizované generování jednotkových testů. Ještě před nimi existovala spousta metod zahrnující příklady jako \textit{fuzzing, generování náhodných testů řízených zpětnou vazbou, dynamické symbolické exekuce, vyhledávvací a evoluční techniky, parametrické testování}. Zároveň také již na počátku století byli pokusy o vytvoření vlastní neuronové sítě sloužící právě čistě k úkolu testování softwaru. V této sekci je ukázka několika z nich. 

            \subsubsection{Programatická řešení}
            Jedna z používaných programatických automatizovaných metod pro tvrobu jednotkových testů je tzv. \textit{fuzzing}. V rámci těchto testů musí uživatel stále definovat jeho kódovou strukturu, resp. akce, které test bude provádět a jaký výstup očekávat. Automaticky generovaný je pouze vstup tohoto testu. Výhodou zde tedy je, že uživatel nemusí vytvářet maketu vstupních dat testu, která se zde vytvoří automatizovaně. Zůstává zde však problematika, že pro uživatele není kód \emph{black-box}, ale celou jeho strukturu včetně požadovaného výstupu musí sám definovat. \cite{fuzzing}

            Pouze vstupy dokáže také generovat metoda \textit{symbolické exekuce}, která postupně analyzuje chování větvení programu. Začíná bez předchozích znalostí a používá řešitel omezení k nalezení vstupů, které prozkoumají nové exekuční cesty. Jakmile jsou testy spuštěny s těmito vstupy, nástroj sleduje cestu, kterou se program ubírá, a aktualizuje svou znalostní bázi \((q)\) s novými podmínkami cesty \((p)\). Tento iterativní proces se opakuje a nadále zpřesňuje sadu známých chování a snaží se maximalizovat pokrytí kódu. Nástroje běžně zvládají různé datové typy a respektují pravidla viditelnosti objektů. Snaží se také používat mock objekty a parametrizované makety k simulaci různých chování vstupů, čímž zlepšuje proces generování testů, aby odhalila potenciální chyby a zajistila komplexní pokrytí kódu testy. \cite{parizek_symbolic_execution} Tato metoda je implementována například v nástroji IntelliTest v rámci IDE \textit{Visual Studio}. Je používáná v kombinaci s \emph{parametrickými testy}, také označovanými jako \acrshort{put}. Ty na rozdíl od tradičních jednotkových testů, které jsou obvykle uzavřené metody, mohou přijímat libovolnou sadu parametrů. Nástroje se pak snaží automaticky generovat (minimální) sadu vstupů, které plně pokryjí kód dosažitelný z testu. Nástroje jako např. \textit{IntelliTest} automaticky generují vstupy pro \arcshort{put}, které pokrývají mnoho exekučních cest testovaného kódu. Každý vstup, který pokrývá jinou cestu, je "serializován" jako jednotkový test. Parametrické testy mohou být také generické metody, v tom případě musí uživatel specifikovat typy použité k instanci metody. Testy také mohou obsahovat atributy pro očekávané a neočekávané vyjímky. Neočekávané vyjímky vedou k selhání testu. \arcshort{put} tedy do velké míry redukují potřebu uživatelského vstupu pro tvorbu jednotkových testů. \cite{IntelliTestInputGeneration2023} \cite{microsoft2023testgen}

            Pokud zvolíme symbolické řešení vstupu společně s determinovanými vstupy a testovací cestou, vzniká tak hybridní řešení zvané jako \emph{konkolické testovaní} nebo \emph{dynamická symbolická exekuce}. Tento druh testů dokáží tvořit nástroje jako \textit{SAGE, KLEE} nebo \textit{S2E}. Problémem tohoto přístupu však je, když program vykazuje \emph{nedeterministické} chování, kdy tyto metody nebudou schopny určit správnou cestu a zároveň tak ani zaručit dobré pokrytí kódu/větví. Velká míra používání stavových proměnných může vést k vysoké výpočetní náročnosti těchto metod a nenalezení praktického řešení. \cite{engler2006exe} \cite{sen2005cute} \cite{zhou2006safedrive}

            Další metodou je \textit{náhodné generování testů řízené zpětnou vazbou}, která je vylepšením pro generování náhodných testů tím, že zahrnuje zpětnou vazbu získanou z provádění testovacích vstupů v průběhu jejich vytváření. Tato technika postupně buduje vstupy tím, že náhodně vybírá metodu volání a hledá argumenty mezi dříve vytvořenými vstupy. Jakmile dojde k sestavená vstupu, je provedena jeho exekuce a výsledek ověřen proti sadě \gls{kontrakt}ů a \glspl{filtr}. Výsledek exekuce určuje, zda je vstup redundantní, proti pravidlům, porušující \gls{kontrakt} nebo užitečný pro generování dalších vstupů. Technika vytváří sadu testů, které se skládají z jednotkových testů pro testované třídy. Úspěšné testy mohou být použity k zajištění faktu, že \glspl{kontrakty} kódu jsou zachovány napříč změnami programu; selhávající testy (porušující jeden nebo více kontraktů) ukazují na potenciální chyby, které by měly být opraveny. Tato metoda dokáže vytvořit nejen vstup pro test, ale i tělo (kód) testu. Ovšem pro uživatele je stále vhodné znát strukturu kódu. \cite{FeedbackDirectedRT}

            Z programatických metod se zdají být nejpokročilejší \emph{evoluční algoritmy} pro generování sad jednotkových testů, využívající přístup založený na vhodnosti, aby vyvíjely testovací případy, které mají za cíl maximalizovat pokrytí kódu a detekci chyb. Tyto algoritmy mohou autonomně generovat testovací vstupy, které jsou navrženy tak, aby prozkoumávaly různé exekuční cesty v aplikaci. Uživatelé mohou interagovat s vygenerovanými testy jakožto s \textit{black-boxem}. Testy se zaměřují na vstupy a výstupy, aniž by potřebovali rozumět vnitřní logice testovaného systému. Tento aspekt evolučního testování je zvláště výhodný při práci se složitými systémy nebo když zdrojový kód není snadno dostupný. Proces iterativně upravuje testovací případy na základě pozorovaných chování, upravuje vstupy pro efektivnější prozkoumání systému a identifikaci potenciálních defektů. Tato metoda podporuje vysokou úroveň automatizace při generování testů, snižuje potřebu manuálního vstupu a umožňuje komplexní pokrytí testů s menším úsilím. \cite{CAMPOS2018207} \cite{abs-2111-05003}

            \subsubsection{Neuronové sítě}
            Ke generování jednotkových testů lze využít i vlastní neuronové sítě. Takové se pokoušeli vytvářet například v práci "Unit test generation using machine learning"\cite{Saes2018UnitTestGeneration}, kde byly testovány primárně RNN a experimentálně CNN sítě (ty však měli problém s větším množstvím tokenů). Modely byli testovány na jazyce Java. Metoda přistupovala k programům jakožto white box, tedy měli k dispozici celý zdrojový kód včetně zkompilovaného bytecodu. Při nejlepší konfiguraci dosáhl výsledek modelu \(70.5\%\) parsovatelného kódu (tedy takového bez chyb) natrénovaný z bezmála 10000 příkladů \textit{zdrojový kód - test}. Výsledek práce je však stále jakýsi "proof of concept", protože zatímco vygenerují částečně použitelný výsledek, je vždy nutný zásah experta, aby mohlo dojít k vytvoření celého testovacího souboru. Takovéto sítě se však mohou silně hodit jako výpomoc programátorovi při psaní testů.

            \subsubsection{Nevýhody současných metod}
            Současné metody generování jednotkových testů, jako je \textit{fuzzing} a \textit{symbolická exekuce}, často vyžadují podrobnou znalost struktury kódu a očekávaných výstupů, což omezuje jejich efektivitu a zvyšuje složitost tvorby testů. Jen některé z těchto metod jsou schopné vygenerovat testy pouze na bázi specifikace (z black box pohledu) bez vnitřní znaloasti kódu. Většina z klasických metod je zároveň schopna generovat pouze vstupy jednotkových testů, ale už ne samotné tělo (kód) testu nebo očekávané výstupy, a tedy pouze složí jako jakási konstra pro programátora, který musí test doimplementovat.

            Velké jazykové modely (\gls{llm}) mohou být atraktivní alternativou, protože pomocí nich lze potenciálně automatizovat generování jak vstupů pro testy, tak přidruženého testovacího kódu, čímž se snižuje potřeba hlubokého porozumění struktuře kódu. S takovým nástrojem není potřeba programátora, ale může s ním pracovat i méně zkušený uživatel (např. \textit{tester}). Dále je zde možnost otestovat kód za pomocí slovní specifikace pro funkci nebo vlastnosti. Takové specifikace se používají napřílad v \textit{aero-space} nebo \textit{automotive} sektoru. \GLS{llm} také mohou objevit všechny možné stavy, které mohou u vstupu nebo výstupu nastat a pokusit se pro ně navrhnout test.
    
        \subsection{Vydané publikace}
        Jeden z poměrně nedávno vydaných článků (září 2023) nazvaný "An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation" \cite{schafer2023empirical} se zabývá využitím velkých jazykových modelů (\gls{llm}) pro automatizované generování jednotkových testů v jazyce JavaScript. Implementovali nástroj s názvem \textbf{TESTPILOT}, který využívá \gls{llm} \textit{gpt3.5-turbo}, \textit{code-cushman-002} od společnosti OpenAI a  také model StarCoder, který vznikl jako komunitní projekt \cite{StarCoder2023}. Vstupní sada pro \gls{llm} obsahovala signatury funkcí, komentáře k dokumentaci a příklady použití. Nástroj byl vyhodnocen na 25 balíčcích npm obsahujících celkem 1684 funkcí API. Vygenerované testy dosáhly pomocí gpt3.5-turbo mediánu pokrytí příkazů 70,2\% a pokrytí větví 52,8\%, čímž překonaly nejmodernější techniku generování testů v jazyce JavaScript zaměřenou na zpětnou vazbu, Nessie.

        Zmíněný model \emph{StarCoder} byl představen v článku "StarCoder: may the source be with you!" \cite{StarCoder2023} z května 2023. Vytvořeny byly konkrétně 2 verze, \textit{StarCoder} a \textit{StarCoderBase}, s 15,5 miliardami parametrů a délkou kontextu 8K. Tyto modely jsou natrénovány na datové sadě nazvané \textit{The Stack}, která obsahuje 1 bilion tokenů z permisivně licencovaných repozitářů GitHub. \textit{StarCoderBase} je vícejazyčný model, který překonává ostatní modely open-source \gls{llm} modely, zatímco \textit{StarCoder} je vyladěná verze speciálně pro Python, která se vyrovná nebo překoná stávající modely zaměřené čistě na Python. Článek poskytuje komplexní hodnocení, které ukazuje, že tyto modely jsou vysoce efektivní v různých úlohách souvisejících s kódem.

        Článek "Exploring the Effectiveness of Large Language Models in Generating Unit Tests" \cite{siddiq2023exploring} z dubna 2023 hodnotí výkonnost tří \gls{llm} - \textit{Codex}, \textit{CodeGen} a \textit{GPT-3.5} - při generování jednotkových testů pro třídy jazyka Java. Studie používá jako vstupní sady dva benchmarky, \href{https://paperswithcode.com/dataset/humaneval-x}{HumanEval} a \href{https://paperswithcode.com/dataset/evosuite-sf110-benchmark}{Evosuite SF110}. Klíčová zjištění ukazují, že \textit{Codex} dosáhl více než 80\% pokrytí v datové sadě \textit{HumanEval}, ale žádný z modelů nedosáhl více než 2\% pokrytí v benchmarku \textit{SF110}. Kromě toho se ve vygenerovaných testech často objevovaly tzv. \gls{testsmells}, jako jsou \textit{duplicitní tvrzení} a \textit{prázdné testy} \cite{testsmells}.

            \subsubsection{Srovnání výsledků}
            Výsledky diskutovaných studií v předchozím bodě jsme srovnali v tabulce \ref{tab:paper_comp}. V rámci první práce dosahuje nejlepších výsledků model \textit{gpt-3.5-turbo}, který dosáhl 70\% pokrytí kódu testy a 48\% úspěšnosti testů. U druhé studie má tento model na testovací sadě \textit{HumanEval} velice podobný výsledek, ovšem model \textit{Codex} dosáhl lepších výsledků. Může však také jít o rozdíl způsobený programovacím jazykem. Zatímco v práci \cite{schafer2023empirical} se využívá jako benchmark sada balíčků jazyka \textit{JavaScript}, který kvůli absenci explicitního typování, může být obtížnější pro strojové testování oproti jazyku Java, který je využit ve zbylých 2 pracích. \cite{jutai} také využívá Javu a s modelem \textit{gpt-3.5-turbo} dosahuje podobného pokrytí kódu a úspěšnosti jako \textit{Codex} v práci \cite{siddiq2023exploring}.

        \subsection{Modely}
            % TODO Tady asi nějaká předmluva k těm modelům a co za modely se vlastně používá 
            Na \GLS{llm} modelech nás konkrétně zajímá schopnost pozorumět progamovacím jazykům a ty poté také generovat na výstupu. Důležité pro nás také je, zda daný model je proprietární či otevřený a pod jakou licencí, tedy zda by byl vhodný pro naši práci. V případě analýzy zdrojového kódu může být také klíčovou vlastností délka kontextu daného modelu. Tyto vlastnosti jsou také zaneseny do tabulky \ref{tab:code_models_comp}.

            Jedním z často používaných modelů v předchozích pracích je \textit{StarCoder} a \textit{StarCoderBase}, diskutovaný již v sekci \ref{sec:previouswork}. \textit{Base} verze je schopna generovat kód pro více jak 80 programovacích jazyků. Model je navržen pro širokou škálu aplikací obsahující \textit{generování}, \textit{modifikaci}, \textit{doplňování} a \textit{vysvětlování} kódu. Jeho distribuce je volná a licence \textbf{CodeML OpenRAIL-M 0.1} \cite{BigCode2023} umožňuje ho využívat pro množštví aplikací včetně komerčních nebo edukačních. Jeho uživatel však má povinnost uvádět, že výsledný kód byl vygenerován modelem. Licence má své restrikce z obavy tvůrců, protože by model mohl někoho při nepsrávném použití ohrozit. Tyto restrikce se aplikují na na všechny derivace projektů pod touto licencí. Zároveň není kompatibilní s Open-Source licencí právě kvůli těmto restrikcím.
            % TODO Tady nechápu ty restrikce

            Nedávno vydaným modelem je \textit{Code Llama} od společnosti Meta. Jedná se o evoluci jejich jazykového modelu \textit{Llama} specializovaný však čistě na úlohy kódování. Je postaven na platformě \textit{Llama 2} a existuje ve třech variantách: \textit{základní Code Llama}, \textit{Code Llama - Python} a \textit{Code Llama - Instruct}. Model podporuje více programovacích jazyků, včetně jazyků jako Python, C++, Java, PHP, Typescript, C# nebo Bash. Je určen pro úlohy, jako je generování kódu, doplňování kódu a ladění. Code Llama je zdarma pro výzkumné i komerční použití a je uvolněn pod licencí MIT. Uživatelé však musí dodržovat  zásady přijatelného použití, ve kterýcg je uvedeno, že model nelze použít k vytvoření služby, která by konkurovala vlastním službám společnosti Meta. 

            Velmi populárním nástrojem pro generování kódu za pomocí \gls{llm} je \href{https://github.com/features/copilot}{GitHub Copilot}, který je postaven na modelu \textit{codex} od OpenAI. Původní model však byl přestal být zákazníkům nabízen a namísto něj OpenAI doporučuje ke generování kódu využívat chat verze modelů GPT-3.5 a GPT-4. Na architektuře GPT-4 je také postavený nástupce služby Copilot, \href{https://github.com/features/preview/copilot-x}{Copilot X}. Zmíněné modely chat GPT-3.5 a GPT-4 jsou primárně určeny pro generování textu formou chatu. Zvládají však zároveň i dobře generovat kód a jsou vhodné i úlohu generování jednotkových testů. Narozdíl od předchozích modelů však nejsou volně distribuovány a jsou poskytovány pouze jako služba společností OpenAI skrze API nebo je lze hostovat v rámci služby Azure společnosti Microsoft, která zajišťuje větší integritu dat. Jedná se tedy o uzavřený model a jeho uživatelé musí souhlasit s jeho podmínkami použití.

            %TODO Existují i další modely, co by bylo super přidat

            \subsubsection{Srovnání modelů}
            Z diskutovaných modelů jsme 3 z nich (\textit{CodeLlama, StarCoderBase a GPT-4}) podrobili vlastnímu testu, kdy jako testovací sada byli využity 4 JavaScript funkce a to ve 3 různých verzích. V první verzi se jednalo o \emph{white box} skript, tedy že modelu byl poskytnut celý obsah funkcí. Dále byli modelům dány pouze \emph{specifikace} funkcí bez jejich těla a poslední verzí je \emph{white box kód s vloženými chybami}. Správná a chybová verze kódu také byla využita pro zhodnocení vygenerovaných funkcí.

            \begin{table}[h]
                \centering
                \begin{tabular}{|l|l|l|l|l|l|l|}
                \hline
                    \textbf{Model} & \multicolumn{2}{c|}{\textbf{CodeLlama}} & \multicolumn{2}{c|}{\textbf{GPT-4}} & \multicolumn{2}{c|}{\textbf{StarCoderBase}} \\ \hline
                Kód           & Správný              & Chybový            & Správný                   & Chybový & Správný                   & Chybový \\ \hline \hline
                    Specifikace            & 4/4        & 3/4           & 4/4 & 3/4                    & 3/4 & 2/4 \\ \hline
                    White box        & 4/4        & 3/4            & 4/4 & 3/4                    & 3/4 & 3/4 \\ \hline
                    Err white box    & 4/4        & 3/4            & 4/4 & 3/4                    & 3/4 & 3/4 \\ \hline
                \end{tabular}
                \caption{Srovnání výsledků generování jednotkových testů za pomocí vybraných modelů.}
                \label{tab:custom_benchmark}
            \end{table}

            Výsledky těchto testů lze nalézt v tabulce \ref{tab:custom_benchmark}. Zatímco u správného kódu bylo hodnoceno, kolik funkcí prošlo testy, tak u funkcí s vloženými chybami se počítá, kolik z nich testy neprošlo. Model \textit{CodeLlama} byl schopný odhalit chybu ve všech funkcích až na jednu. Všechny správné funkce prošli. Je zde však nutné dodat, že generování je velmi pomalé a výstup velice jednoduchý. Nebyl zde náznak o netriviální assert, ovšem pokud se model bude správně promptovat, lze jeho vygenerovaný test dobře využít. \textit{GPT-4} poté měl stejnou úspěšnost jako předchozí model, ovšem i zde byl problém s netriviální asercí. Jednotlivé errory jsou však dobře otestované a výhodou je, že model je rychlý a není tedy v případě nevhodně vygenrovaného testu ho ziterovat a vylepšit na bázi zpětné vazby (\emph{multi-shot}). Při tomto přístupu je poté schopen i netriviálních asercí. Je však potřeba tento model dobře promptovat a výstup může být složitější pro parsování. Model \textit{StarCoderBase} dle výsledků má nejméně úspěšných testů. Ovšem když zanalyzujeme výstupní kód (testy), dojdeme k zajímavému zjištění. Tento model dokázal odchytit i netriviální chyby přímo ze specifikace a zároveň se mu povedlo obejít nepřesnosti ve specifikaci, tedy neúspěšné testy na správném kódu byli stále v rámci specifikace, jen ne ve smyslu, jak byla speficikace zamýšlena. Subjetivně řečeno, \textit{StarCoderBase} dělá správné úsudky a i kód je velice obsáhlý. S přihlédnutím na jeho otevřenost a licenci se jeví jako vhodný model právě pro naši práci.

            \newpage

            \begin{landscape}
                \centering
                \begin{table}[H]
                    \begin{tabular}{|p{6cm}|c|c|c|c|}
                        \hline
                        \textbf{Práce} & \textbf{Model} & \textbf{Benchmark} & \textbf{Pokrytí testy} & \textbf{Úspěšnost} \\
                        \hline
                        \multirow{3}{6cm}{An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation} & \textit{gpt-3.5-turbo} & \multirow{3}{*}{Sada NPM balíčků} & 70.2\% & 48\% \\
                         & \textit{code-cushman-002} & & 68.2\% & 47.1\% \\
                         & \textit{StarCoder} & & 54\% & 31.5\% \\
                        \hline
                        \multirow{6}{6cm}{Exploring the Effectiveness of Large Language
Models in Generating Unit Tests} & \multirow{2}{*}{\textit{gpt-3.5-turbo}} & HumanEval & 69.1\% & 52.3\% \\
                         & & SF110 & 0.1\% & 6.9\% \\
                         & \multirow{2}{*}{\textit{CodeGen}} & HumanEval & 58.2\% & 23.9\% \\
                         & & SF110 & 0.5\% & 30.2\% \\
                         & \multirow{2}{*}{\textit{Codex (4k)}} & HumanEval & 87.7\% & 76.7\% \\
                         & & SF110 & 1.8\% & 41.1\% \\
                        \hline
                        Java Unit Testing with AI: An AI-Driven Prototype for Unit Test Generation & \textit{gpt-3.5-turbo} & JUTAI - Zero-shot, temperature: \(0\) & 84.7\% & 71\% \\
                        \hline
                    \end{tabular}
                    \centering
                    \caption{Přehled a srovnání studií}
                    \label{tab:paper_comp}
                \end{table}
                \begin{table}[H]
                    \begin{tabular}{|c|c|c|c|c|c|}
                        \hline
                        \textbf{Model} & \textbf{Otevřenost} & \textbf{Licence} & \textbf{Počet parametrů} & \textbf{Počet programovacích jazyků} & \textbf{Datum vydání} \\
                        \hline
                        \textit{StarCoderBase} & Volně dostupný & CodeML OpenRAIL-M 0.1 & 15.5 miliardy & 80+ & 5/2023 \\
                        \hline
                        \textit{Code Llama} & Volně dostupný & Llama 2 Licence & 34 miliard & 8+ & 8/2023 \\
                        \hline
                        \textit{gpt-3.5-turbo} & Uzavřený & Proprietární & 175 miliard? & ? & 5/2023 \\
                        \hline
                        \textit{gpt-4} & Uzavřený & Proprietární & 1.76 bilionu & ? & 3/2023 \\
                        \hline
                    \end{tabular}
                    \centering
                    \caption{Přehled a srovnání modelů generujících kód}
                    \label{tab:code_models_comp}
                \end{table} 
            \end{landscape}

    % Reference
    \newpage
    \bibliographystyle{ieeetr}
    \bibliography{refs}
	
\end{document}
