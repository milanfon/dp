% *****************************************************************************
%
%        FASThesis Manual
%        (FASThesis Class File Documentation)
%
%        Faculty of Applied Sciences
%        University of West Bohemia
%
%        Manual & Explanatory Document
%        Copyright (c) 2022-2024 Kamil Ekštein, Dept. of Computer Science
%        and Engineering, Faculty of Applied Sciences, UWB
%
%        Version:  0.96
%		 Encoding: UTF-8
%		 TeXer:    pdflatex
%
%        Last modification on 11-Apr-2024 by KE
%
% *****************************************************************************

% _____________________________________________________________________________
%
%
%	     DOCUMENT HEADER
%
% _____________________________________________________________________________
%
\documentclass[czech, ma, kiv, he, iso690alph, pdf, viewonly]{fasthesis}
\title{Generování jednotkových testů s využitím LLM}
\author{Milan}{Horínek}{Bc.}{}
\supervisor{Ing. Richard Lipka, Ph.D.}
\stagworkid{12345}% <== the unique identifier of the work in the STAG information system
\assignment{zadani.pdf}
\signdate{14}{05}{2024}{Plzeň}% <== the longest local name in the Czech Rep.

\usepackage[acronym]{glossaries}
\usepackage{pdflscape}
\usepackage{multirow}

% Slovník
\makeglossaries
\input{gloss.tex}

\addbibresource{dp.bib}% <== the file with the bibliographical database to be used throughout the text
% _____________________________________________________________________________
%
%
%	     DOCUMENT FRONTMATTER TEXTS
%
% _____________________________________________________________________________
%
\abstract{TBD}
% *** English abstract ***
{TBD}
\keywords{LLM, testing, unit, Robot Framework}
% _____________________________________________________________________________
%
%        ACKNOWLEDGEMENT
% _____________________________________________________________________________
%
\acknowledgement{TBD}

% Gloss
\auxfrontmattercontent{
    \printglossary[type=\acronymtype,title=Zkratky]
    \printglossary[title=Slovník pojmů]
}
% _____________________________________________________________________________
%
%
%	     DOCUMENT TEXT BEGINNING
%
% ____________________________________________________________________________
%
\begin{document}
\frontpages[tm] % or notm if the `trademark' declaration is not needed
\tableofcontents
% 
% -x---- ADDITIONAL COLOUR DEFINITIONS ----------------------------------------
%
\makeatletter%
\ifx\FASThesis@style\c@fullcolor%
	\definecolor{fascolor}{cmyk}{0.06, 0.27, 1.0, 0.12}%
	\definecolor{fascolordk}{cmyk}{0.05, 0.28, 1.0, 0.24}%
\else%
	\definecolor{fascolor}{cmyk}{0, 0, 0, 0.6}%
	\definecolor{fascolordk}{cmyk}{0, 0, 0, 0.75}%
\fi%
\makeatother%
\lstdefinestyle{plainsrc}{
	backgroundcolor=\color{fascolor!10},
	basicstyle=\ttfamily\footnotesize,
	numberstyle=\tiny\color{fascolordk},
	numbers=left,
	numbersep=5pt,
	keepspaces=true,
	tabsize=2,
	extendedchars=true,
	literate={á}{{\'a}}1 {č}{{\v{c}}}1 {ď}{{\v{d}}}1 {é}{{\'e}}1 {ě}{{\v{e}}}1 {è}{{\`{e}}}1 {í}{{\'{\i}}}1 {ľ}{{\v{l}}}1 {ň}{{\v{n}}}1 {ó}{{\'o}}1 {ŕ}{{\'r}}1 {ř}{{\v{r}}}1 {š}{{\v{s}}}1 {ť}{{\v{t}}}1 {ú}{{\'u}}1 {ů}{{\r{u}}}1 {ý}{{\'y}}1 {ž}{{\v{z}}}1
	{Á}{{\'A}}1 {Č}{{\v{C}}}1 {Ď}{{\v{D}}}1 {É}{{\'E}}1 {Ě}{{\v{E}}}1 {È}{{\`{E}}}1 {Í}{{\'I}}1 {Ľ}{{\v{L}}}1 {Ň}{{\v{N}}}1 {Ó}{{\'O}}1 {Ŕ}{{\'R}}1 {Ř}{{\v{R}}}1 {Š}{{\v{S}}}1 {Ť}{{\v{T}}}1 {Ú}{{\'U}}1 {Ů}{{\r{U}}}1 {Ý}{{\'Y}}1 {Ž}{{\v{Z}}}1
}

\setlength{\parskip}{1em}
% -x---- END OF ADDITIONAL COLOUR DEFINITIONS ---------------------------------


\chapter{Úvod}
TDB - Co jsou unit testy, LLM, a jejich předpoklady, GUI testování



\chapter{Rešerše}

    \section{Provedená práce v problematice} \label{sec:previouswork}
        \subsection{Předchozí automatizovaná řešení}
        Jazykové modely nebyli prvními pokusy o automatizované generování jednotkových testů. Ještě před nimi existovala spousta metod zahrnující příklady jako \textit{fuzzing, generování náhodných testů řízených zpětnou vazbou, dynamické symbolické exekuce, vyhledávvací a evoluční techniky, parametrické testování}. Zároveň také již na počátku století byli pokusy o vytvoření vlastní neuronové sítě sloužící právě čistě k úkolu testování softwaru. V této sekci je ukázka několika z nich. 


        \subsubsection{Programatická řešení}
        Jedna z používaných programatických automatizovaných metod pro tvrobu jednotkových testů je tzv. \textit{fuzzing}. V rámci těchto testů musí uživatel stále definovat jeho kódovou strukturu, resp. akce, které test bude provádět a jaký výstup očekávat. Automaticky generovaný je pouze vstup tohoto testu. Výhodou zde tedy je, že uživatel nemusí vytvářet maketu vstupních dat testu, která se zde vytvoří automatizovaně. Zůstává zde však problematika, že pro uživatele není kód \emph{black-box}, ale celou jeho strukturu včetně požadovaného výstupu musí sám definovat. \cite{fuzzing}

        Pouze vstupy dokáže také generovat metoda \textit{symbolické exekuce}, která postupně analyzuje chování větvení programu. Začíná bez předchozích znalostí a používá řešitel omezení k nalezení vstupů, které prozkoumají nové exekuční cesty. Jakmile jsou testy spuštěny s těmito vstupy, nástroj sleduje cestu, kterou se program ubírá, a aktualizuje svou znalostní bázi \((q)\) s novými podmínkami cesty \((p)\). Tento iterativní proces se opakuje a nadále zpřesňuje sadu známých chování a snaží se maximalizovat pokrytí kódu. Nástroje běžně zvládají různé datové typy a respektují pravidla viditelnosti objektů. Snaží se také používat mock objekty a parametrizované makety k simulaci různých chování vstupů, čímž zlepšuje proces generování testů, aby odhalila potenciální chyby a zajistila komplexní pokrytí kódu testy. \cite{parizek_symbolic_execution} Tato metoda je implementována například v nástroji IntelliTest v rámci IDE \textit{Visual Studio}. Je používáná v kombinaci s \emph{parametrickými testy}, také označovanými jako \acrshort{put}. Ty na rozdíl od tradičních jednotkových testů, které jsou obvykle uzavřené metody, mohou přijímat libovolnou sadu parametrů. Nástroje se pak snaží automaticky generovat (minimální) sadu vstupů, které plně pokryjí kód dosažitelný z testu. Nástroje jako např. \textit{IntelliTest} automaticky generují vstupy pro \arcshort{put}, které pokrývají mnoho exekučních cest testovaného kódu. Každý vstup, který pokrývá jinou cestu, je "serializován" jako jednotkový test. Parametrické testy mohou být také generické metody, v tom případě musí uživatel specifikovat typy použité k instanci metody. Testy také mohou obsahovat atributy pro očekávané a neočekávané vyjímky. Neočekávané vyjímky vedou k selhání testu. \arcshort{put} tedy do velké míry redukují potřebu uživatelského vstupu pro tvorbu jednotkových testů. \cite{IntelliTestInputGeneration2023} \cite{microsoft2023testgen}

        Pokud zvolíme symbolické řešení vstupu společně s determinovanými vstupy a testovací cestou, vzniká tak hybridní řešení zvané jako \emph{konkolické testovaní} nebo \emph{dynamická symbolická exekuce}. Tento druh testů dokáží tvořit nástroje jako \textit{SAGE, KLEE} nebo \textit{S2E}. Problémem tohoto přístupu však je, když program vykazuje \emph{nedeterministické} chování, kdy tyto metody nebudou schopny určit správnou cestu a zároveň tak ani zaručit dobré pokrytí kódu/větví. Velká míra používání stavových proměnných může vést k vysoké výpočetní náročnosti těchto metod a nenalezení praktického řešení. \cite{engler2006exe} \cite{sen2005cute} \cite{zhou2006safedrive}

        Další metodou je \textit{náhodné generování testů řízené zpětnou vazbou}, která je vylepšením pro generování náhodných testů tím, že zahrnuje zpětnou vazbu získanou z provádění testovacích vstupů v průběhu jejich vytváření. Tato technika postupně buduje vstupy tím, že náhodně vybírá metodu volání a hledá argumenty mezi dříve vytvořenými vstupy. Jakmile dojde k sestavená vstupu, je provedena jeho exekuce a výsledek ověřen proti sadě \gls{kontrakt}ů a \glspl{filtr}. Výsledek exekuce určuje, zda je vstup redundantní, proti pravidlům, porušující \gls{kontrakt} nebo užitečný pro generování dalších vstupů. Technika vytváří sadu testů, které se skládají z jednotkových testů pro testované třídy. Úspěšné testy mohou být použity k zajištění faktu, že \glspl{kontrakty} kódu jsou zachovány napříč změnami programu; selhávající testy (porušující jeden nebo více kontraktů) ukazují na potenciální chyby, které by měly být opraveny. Tato metoda dokáže vytvořit nejen vstup pro test, ale i tělo (kód) testu. Ovšem pro uživatele je stále vhodné znát strukturu kódu. \cite{FeedbackDirectedRT}

        Z programatických metod se zdají být nejpokročilejší \emph{evoluční algoritmy} pro generování sad jednotkových testů, využívající přístup založený na vhodnosti, aby vyvíjely testovací případy, které mají za cíl maximalizovat pokrytí kódu a detekci chyb. Tyto algoritmy mohou autonomně generovat testovací vstupy, které jsou navrženy tak, aby prozkoumávaly různé exekuční cesty v aplikaci. Uživatelé mohou interagovat s vygenerovanými testy jakožto s \textit{black-boxem}. Testy se zaměřují na vstupy a výstupy, aniž by potřebovali rozumět vnitřní logice testovaného systému. Tento aspekt evolučního testování je zvláště výhodný při práci se složitými systémy nebo když zdrojový kód není snadno dostupný. Proces iterativně upravuje testovací případy na základě pozorovaných chování, upravuje vstupy pro efektivnější prozkoumání systému a identifikaci potenciálních defektů. Tato metoda podporuje vysokou úroveň automatizace při generování testů, snižuje potřebu manuálního vstupu a umožňuje komplexní pokrytí testů s menším úsilím. \cite{CAMPOS2018207} \cite{abs-2111-05003}

        \subsubsection{Neuronové sítě}
        Ke generování jednotkových testů lze využít i vlastní neuronové sítě. Takové se pokoušeli vytvářet například v práci "Unit test generation using machine learning"\cite{Saes2018UnitTestGeneration}, kde byly testovány primárně RNN a experimentálně CNN sítě (ty však měli problém s větším množstvím tokenů). Modely byli testovány na jazyce Java. Metoda přistupovala k programům jakožto white box, tedy měli k dispozici celý zdrojový kód včetně zkompilovaného bytecodu. Při nejlepší konfiguraci dosáhl výsledek modelu \(70.5\%\) parsovatelného kódu (tedy takového bez chyb) natrénovaný z bezmála 10000 příkladů \textit{zdrojový kód - test}. Výsledek práce je však stále jakýsi "proof of concept", protože zatímco vygenerují částečně použitelný výsledek, je vždy nutný zásah experta, aby mohlo dojít k vytvoření celého testovacího souboru. Takovéto sítě se však mohou silně hodit jako výpomoc programátorovi při psaní testů.

        \subsubsection{Nevýhody současných metod}
        Současné metody generování jednotkových testů, jako je \textit{fuzzing} a \textit{symbolická exekuce}, často vyžadují podrobnou znalost struktury kódu a očekávaných výstupů, což omezuje jejich efektivitu a zvyšuje složitost tvorby testů. Jen některé z těchto metod jsou schopné vygenerovat testy pouze na bázi specifikace (z black box pohledu) bez vnitřní znaloasti kódu. Většina z klasických metod je zároveň schopna generovat pouze vstupy jednotkových testů, ale už ne samotné tělo (kód) testu nebo očekávané výstupy, a tedy pouze složí jako jakási konstra pro programátora, který musí test doimplementovat.

        Velké jazykové modely (\gls{llm}) mohou být atraktivní alternativou, protože pomocí nich lze potenciálně automatizovat generování jak vstupů pro testy, tak přidruženého testovacího kódu, čímž se snižuje potřeba hlubokého porozumění struktuře kódu. S takovým nástrojem není potřeba programátora, ale může s ním pracovat i méně zkušený uživatel (např. \textit{tester}). Dále je zde možnost otestovat kód za pomocí slovní specifikace pro funkci nebo vlastnosti. Takové specifikace se používají napřílad v \textit{aero-space} nebo \textit{automotive} sektoru. \GLS{llm} také mohou objevit všechny možné stavy, které mohou u vstupu nebo výstupu nastat a pokusit se pro ně navrhnout test.

    \subsection{Vydané publikace}
    Jeden z poměrně nedávno vydaných článků (září 2023) nazvaný "An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation" \cite{schafer2023empirical} se zabývá využitím velkých jazykových modelů (\gls{llm}) pro automatizované generování jednotkových testů v jazyce JavaScript. Implementovali nástroj s názvem \textbf{TESTPILOT}, který využívá \gls{llm} \textit{gpt3.5-turbo}, \textit{code-cushman-002} od společnosti OpenAI a  také model StarCoder, který vznikl jako komunitní projekt \cite{StarCoder2023}. Vstupní sada pro \gls{llm} obsahovala signatury funkcí, komentáře k dokumentaci a příklady použití. Nástroj byl vyhodnocen na 25 balíčcích npm obsahujících celkem 1684 funkcí API. Vygenerované testy dosáhly pomocí gpt3.5-turbo mediánu pokrytí příkazů 70,2\% a pokrytí větví 52,8\%, čímž překonaly nejmodernější techniku generování testů v jazyce JavaScript zaměřenou na zpětnou vazbu, Nessie.

    Zmíněný model \emph{StarCoder} byl představen v článku "StarCoder: may the source be with you!" \cite{StarCoder2023} z května 2023. Vytvořeny byly konkrétně 2 verze, \textit{StarCoder} a \textit{StarCoderBase}, s 15,5 miliardami parametrů a délkou kontextu 8K. Tyto modely jsou natrénovány na datové sadě nazvané \textit{The Stack}, která obsahuje 1 bilion tokenů z permisivně licencovaných repozitářů GitHub. \textit{StarCoderBase} je vícejazyčný model, který překonává ostatní modely open-source \gls{llm} modely, zatímco \textit{StarCoder} je vyladěná verze speciálně pro Python, která se vyrovná nebo překoná stávající modely zaměřené čistě na Python. Článek poskytuje komplexní hodnocení, které ukazuje, že tyto modely jsou vysoce efektivní v různých úlohách souvisejících s kódem.

    Článek "Exploring the Effectiveness of Large Language Models in Generating Unit Tests" \cite{siddiq2023exploring} z dubna 2023 hodnotí výkonnost tří \gls{llm} - \textit{Codex}, \textit{CodeGen} a \textit{GPT-3.5} - při generování jednotkových testů pro třídy jazyka Java. Studie používá jako vstupní sady dva benchmarky, \href{https://paperswithcode.com/dataset/humaneval-x}{HumanEval} a \href{https://paperswithcode.com/dataset/evosuite-sf110-benchmark}{Evosuite SF110}. Klíčová zjištění ukazují, že \textit{Codex} dosáhl více než 80\% pokrytí v datové sadě \textit{HumanEval}, ale žádný z modelů nedosáhl více než 2\% pokrytí v benchmarku \textit{SF110}. Kromě toho se ve vygenerovaných testech často objevovaly tzv. \gls{testsmells}, jako jsou \textit{duplicitní tvrzení} a \textit{prázdné testy} \cite{testsmells}.

    \subsubsection{Srovnání výsledků}
    Výsledky diskutovaných studií v předchozím bodě jsme srovnali v tabulce \ref{tab:paper_comp}. V rámci první práce dosahuje nejlepších výsledků model \textit{gpt-3.5-turbo}, který dosáhl 70\% pokrytí kódu testy a 48\% úspěšnosti testů. U druhé studie má tento model na testovací sadě \textit{HumanEval} velice podobný výsledek, ovšem model \textit{Codex} dosáhl lepších výsledků. Může však také jít o rozdíl způsobený programovacím jazykem. Zatímco v práci \cite{schafer2023empirical} se využívá jako benchmark sada balíčků jazyka \textit{JavaScript}, který kvůli absenci explicitního typování, může být obtížnější pro strojové testování oproti jazyku Java, který je využit ve zbylých 2 pracích. \cite{jutai} také využívá Javu a s modelem \textit{gpt-3.5-turbo} dosahuje podobného pokrytí kódu a úspěšnosti jako \textit{Codex} v práci \cite{siddiq2023exploring}.


    \subsection{Modely}
    % TODO Tady asi nějaká předmluva k těm modelům a co za modely se vlastně používá 
    Na \GLS{llm} modelech nás konkrétně zajímá schopnost pozorumět progamovacím jazykům a ty poté také generovat na výstupu. Důležité pro nás také je, zda daný model je proprietární či otevřený a pod jakou licencí, tedy zda by byl vhodný pro naši práci. V případě analýzy zdrojového kódu může být také klíčovou vlastností délka kontextu daného modelu. Tyto vlastnosti jsou také zaneseny do tabulky \ref{tab:code_models_comp}.

    Jedním z často používaných modelů v předchozích pracích je \textit{StarCoder} a \textit{StarCoderBase}, diskutovaný již v sekci \ref{sec:previouswork}. \textit{Base} verze je schopna generovat kód pro více jak 80 programovacích jazyků. Model je navržen pro širokou škálu aplikací obsahující \textit{generování}, \textit{modifikaci}, \textit{doplňování} a \textit{vysvětlování} kódu. Jeho distribuce je volná a licence \textbf{CodeML OpenRAIL-M 0.1} \cite{BigCode2023} umožňuje ho využívat pro množštví aplikací včetně komerčních nebo edukačních. Jeho uživatel však má povinnost uvádět, že výsledný kód byl vygenerován modelem. Licence má své restrikce z obavy tvůrců, protože by model mohl někoho při nepsrávném použití ohrozit. Tyto restrikce se aplikují na na všechny derivace projektů pod touto licencí. Zároveň není kompatibilní s Open-Source licencí právě kvůli těmto restrikcím.
    % TODO Tady nechápu ty restrikce

    Nedávno vydaným modelem je \textit{Code Llama} od společnosti Meta. Jedná se o evoluci jejich jazykového modelu \textit{Llama} specializovaný však čistě na úlohy kódování. Je postaven na platformě \textit{Llama 2} a existuje ve třech variantách: \textit{základní Code Llama}, \textit{Code Llama - Python} a \textit{Code Llama - Instruct}. Model podporuje více programovacích jazyků, včetně jazyků jako Python, C++, Java, PHP, Typescript, C# nebo Bash. Je určen pro úlohy, jako je generování kódu, doplňování kódu a ladění. Code Llama je zdarma pro výzkumné i komerční použití a je uvolněn pod licencí MIT. Uživatelé však musí dodržovat  zásady přijatelného použití, ve kterých je uvedeno, že model nelze použít k vytvoření služby, která by konkurovala vlastním službám společnosti Meta. 

    Velmi populárním nástrojem pro generování kódu za pomocí \gls{llm} je \href{https://github.com/features/copilot}{GitHub Copilot}, který je postaven na modelu \textit{codex} od OpenAI. Původní model však byl přestal být zákazníkům nabízen a namísto něj OpenAI doporučuje ke generování kódu využívat chat verze modelů GPT-3.5 a GPT-4. Na architektuře GPT-4 je také postavený nástupce služby Copilot, \href{https://github.com/features/preview/copilot-x}{Copilot X}. Zmíněné modely chat GPT-3.5 a GPT-4 jsou primárně určeny pro generování textu formou chatu. Zvládají však zároveň i dobře generovat kód a jsou vhodné i úlohu generování jednotkových testů. Narozdíl od předchozích modelů však nejsou volně distribuovány a jsou poskytovány pouze jako služba společností OpenAI skrze API nebo je lze hostovat v rámci služby Azure společnosti Microsoft, která zajišťuje větší integritu dat. Jedná se tedy o uzavřený model a jeho uživatelé musí souhlasit s jeho podmínkami použití.

    %TODO Existují i další modely, co by bylo super přidat

        \subsubsection{Srovnání modelů}
        Z diskutovaných modelů jsme 3 z nich (\textit{CodeLlama, StarCoderBase a GPT-4}) podrobili vlastnímu testu, kdy jako testovací sada byli využity 4 JavaScript funkce a to ve 3 různých verzích. V první verzi se jednalo o \emph{white box} skript, tedy že modelu byl poskytnut celý obsah funkcí. Dále byli modelům dány pouze \emph{specifikace} funkcí bez jejich těla a poslední verzí je \emph{white box kód s vloženými chybami}. Správná a chybová verze kódu také byla využita pro zhodnocení vygenerovaných funkcí.

        \begin{table}[h]
            \centering
            \begin{tabular}{|l|l|l|l|l|l|l|}
            \hline
                \textbf{Model} & \multicolumn{2}{c|}{\textbf{CodeLlama}} & \multicolumn{2}{c|}{\textbf{GPT-4}} & \multicolumn{2}{c|}{\textbf{StarCoderBase}} \\ \hline
            Kód           & Správný              & Chybový            & Správný                   & Chybový & Správný                   & Chybový \\ \hline \hline
                Specifikace            & 4/4        & 3/4           & 4/4 & 3/4                    & 3/4 & 2/4 \\ \hline
                White box        & 4/4        & 3/4            & 4/4 & 3/4                    & 3/4 & 3/4 \\ \hline
                Err white box    & 4/4        & 3/4            & 4/4 & 3/4                    & 3/4 & 3/4 \\ \hline
            \end{tabular}
            \caption{Srovnání výsledků generování jednotkových testů za pomocí vybraných modelů.}
            \label{tab:custom_benchmark}
        \end{table}

        Výsledky těchto testů lze nalézt v tabulce \ref{tab:custom_benchmark}. Zatímco u správného kódu bylo hodnoceno, kolik funkcí prošlo testy, tak u funkcí s vloženými chybami se počítá, kolik z nich testy neprošlo. Model \textit{CodeLlama} byl schopný odhalit chybu ve všech funkcích až na jednu. Všechny správné funkce prošli. Je zde však nutné dodat, že generování je velmi pomalé a výstup velice jednoduchý. Nebyl zde náznak o netriviální assert, ovšem pokud se model bude správně promptovat, lze jeho vygenerovaný test dobře využít. \textit{GPT-4} poté měl stejnou úspěšnost jako předchozí model, ovšem i zde byl problém s netriviální asercí. Jednotlivé errory jsou však dobře otestované a výhodou je, že model je rychlý a není tedy v případě nevhodně vygenrovaného testu ho ziterovat a vylepšit na bázi zpětné vazby (\emph{multi-shot}). Při tomto přístupu je poté schopen i netriviálních asercí. Je však potřeba tento model dobře promptovat a výstup může být složitější pro parsování. Model \textit{StarCoderBase} dle výsledků má nejméně úspěšných testů. Ovšem když zanalyzujeme výstupní kód (testy), dojdeme k zajímavému zjištění. Tento model dokázal odchytit i netriviální chyby přímo ze specifikace a zároveň se mu povedlo obejít nepřesnosti ve specifikaci, tedy neúspěšné testy na správném kódu byli stále v rámci specifikace, jen ne ve smyslu, jak byla speficikace zamýšlena. Subjetivně řečeno, \textit{StarCoderBase} dělá správné úsudky a i kód je velice obsáhlý. S přihlédnutím na jeho otevřenost a licenci se jeví jako vhodný model právě pro naši práci.

        \newpage

        \begin{landscape}
            \centering
            \begin{table}[H]
                \begin{tabular}{|p{6cm}|c|c|c|c|}
                    \hline
                    \textbf{Práce} & \textbf{Model} & \textbf{Benchmark} & \textbf{Pokrytí testy} & \textbf{Úspěšnost} \\
                    \hline
                    \multirow{3}{6cm}{An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation} & \textit{gpt-3.5-turbo} & \multirow{3}{*}{Sada NPM balíčků} & 70.2\% & 48\% \\
                     & \textit{code-cushman-002} & & 68.2\% & 47.1\% \\
                     & \textit{StarCoder} & & 54\% & 31.5\% \\
                    \hline
                    \multirow{6}{6cm}{Exploring the Effectiveness of Large Language
Models in Generating Unit Tests} & \multirow{2}{*}{\textit{gpt-3.5-turbo}} & HumanEval & 69.1\% & 52.3\% \\
                     & & SF110 & 0.1\% & 6.9\% \\
                     & \multirow{2}{*}{\textit{CodeGen}} & HumanEval & 58.2\% & 23.9\% \\
                     & & SF110 & 0.5\% & 30.2\% \\
                     & \multirow{2}{*}{\textit{Codex (4k)}} & HumanEval & 87.7\% & 76.7\% \\
                     & & SF110 & 1.8\% & 41.1\% \\
                    \hline
                    Java Unit Testing with AI: An AI-Driven Prototype for Unit Test Generation & \textit{gpt-3.5-turbo} & JUTAI - Zero-shot, temperature: \(0\) & 84.7\% & 71\% \\
                    \hline
                \end{tabular}
                \centering
                \caption{Přehled a srovnání studií}
                \label{tab:paper_comp}
            \end{table}
            \begin{table}[H]
                \begin{tabular}{|c|c|c|c|c|c|}
                    \hline
                    \textbf{Model} & \textbf{Otevřenost} & \textbf{Licence} & \textbf{Počet parametrů} & \textbf{Počet programovacích jazyků} & \textbf{Datum vydání} \\
                    \hline
                    \textit{StarCoderBase} & Volně dostupný & CodeML OpenRAIL-M 0.1 & 15.5 miliardy & 80+ & 5/2023 \\
                    \hline
                    \textit{Code Llama} & Volně dostupný & Llama 2 Licence & 34 miliard & 8+ & 8/2023 \\
                    \hline
                    \textit{gpt-3.5-turbo} & Uzavřený & Proprietární & 175 miliard? & ? & 5/2023 \\
                    \hline
                    \textit{gpt-4} & Uzavřený & Proprietární & 1.76 bilionu & ? & 3/2023 \\
                    \hline
                \end{tabular}
                \centering
                \caption{Přehled a srovnání modelů generujících kód}
                \label{tab:code_models_comp}
            \end{table} 
        \end{landscape}


\chapter{Bla}

% _____________________________________________________________________________
%
%
%        BACK MATTER (BIBLIOGRAPHY, LISTS, ...)
%
% _____________________________________________________________________________
%
\backmatter
\printbibliography
\listoffigures
\listoftables
\listoflistings
% _____________________________________________________________________________
%
%		BACK COVER
% _____________________________________________________________________________
%
%\setbackpagepic{img/fav} % <== an example of one possible option (read this manual)
%\setqrcodebaseurl{https://mycloud.org/show=pdf&docid=} % <== another example
%\setbackpageqrcode{54321} % <== and one more (uncomment the one that makes sense for you)
\setbackpageqrcode
\backpage
\end{document}
