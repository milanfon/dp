- Deploy
    - Pojede na serveru bez grafiky?
    - Potřebuje XServ nebo Wayland
- ✅  Úprava vstupů v pipelině
- ✅  Možnost variace některých vstupů (např. ze souboru)
- Zatím jeden obecný prompt pro všechny modely
    - Tweaknutá varianta pokud zbyde čas + poprvnání
- ❌  Zkusil ukládat seedy
- ✅ U každého testu zkusit tak 10 varian
- Začátek testu vždy stejný

## Otázky

- Budou tokeny na OpenAI? 
    - Jakoby zatím jsem to udělal manuálně jako copy paste to chatu, ale mít i přímo přístup k API by bylo fajn
- Ukládání seedů je trochu problém
    - Ne všechny druhy modelů umoňují nastavit seedy
    - Někdy jich je více
    - Nenašel jsem model/framework. kde to jde vytáhnout ven při rng generaci
    - Když seed jde nastavit, tak ten model stále negeneruje vždycky ty stejné výsledky. Jsou tam nějaké odlišnosti. Vypadá to dost podobně, ale není to vyloženě stejné. 
- Mám 
    - Vytváření templatu pro test
    - Generování testu dle templatu
- Variace testů soubory vyřešena skrze templating pomocí knihovny Jinja2
- Jak ukládat výsledky?
    - Piping?
    - Report?
    - Strojově parsovat výstup? 
    - Zkusit nahrát do jiného modelu?

- Jak mají vypadat statistiky? 
- Jak moc detailně popisovat specifikace
- Vyplatilo by zkusit to i krokovat? 
    - Uživatel nebude nahrávat celý use case, ale jednolivé části kroků, které na sebe budou navazovat a dohromady tvořit jednotný test
- Problémem je kontext
    - Častokrát modely (resp. runtime) mají moc malý kontext, což pro nahrávání recordingů je problém
    - Zjednodušený formát recordingu? 
- Vvyplatilo by se udělat něco jako "test groups"?
- Předvést kompresi
- Zeptat se, co zapsat za projekt

## TODO
- ✅  Parsování výstupu modelů
    - Zůstává tam md
- Prompt engineering
    - U jednoho modelu (nejspíš lokální)
    - Vede jiný prompt k lepšímu výsledku? (zkusit třeba 4)
- Zkusit jen 8 poruchových modelů a pro ně související specifikace
